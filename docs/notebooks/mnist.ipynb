{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc161ca8b1fbb2bd451e3d2099397e8",
   "metadata": {},
   "source": [
    "# MNIST: Digits Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3849c6325bbe19d03783854b2aa09",
   "metadata": {
    "tags": [
     "add-colab-badge"
    ]
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unionai-oss/unionml/blob/main/docs/notebooks/mnist.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3016ed437b301660e8b1f547344ab",
   "metadata": {},
   "source": [
    "The MNIST dataset is considered to be the \"hello world\" example of machine\n",
    "learning. In that same spirit, we'll be making the \"hello world\" UnionML app\n",
    "using this dataset and a simple linear classifier with\n",
    "[sklearn](https://scikit-learn.org/stable/index.html).\n",
    "\n",
    "With this dataset, we'll see just how easy it is to create a single-script UnionML app.\n",
    "\n",
    "```{note}\n",
    "This tutorial is adapted from this [sklearn guide](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_mnist.html).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6123a3d4f4e9b5147540d6b894b9f131",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install 'gradio<=3.0.10' pandas sklearn unionml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94047af90e218c12194e7419b3750cfe",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "> If you're running this notebook in google colab, you need to restart the kernel to\n",
    "> make sure that the newly installed packages are correctly imported in the next line below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d457786e49cc8827b76aebe831996d3c",
   "metadata": {},
   "source": [
    "First let's import our dependencies and create the UnionML `Dataset` and `Model`\n",
    "objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107cd0e66e368a4db938ff3d8f70fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from unionml import Dataset, Model\n",
    "\n",
    "\n",
    "dataset = Dataset(name=\"mnist_dataset\", test_size=0.2, shuffle=True, targets=[\"class\"])\n",
    "model = Model(name=\"mnist_classifier\", init=LogisticRegression, dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48580216854e9ef4115087ac11530a6",
   "metadata": {},
   "source": [
    "For convenience, we cache the dataset so that MNIST loading is faster upon subsequent calls\n",
    "to the `fetch_openml` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25708b9684693f818c3d4148b2c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from joblib import Memory\n",
    "\n",
    "memory = Memory(Path.home() / \"tmp\")\n",
    "fetch_openml_cached = memory.cache(fetch_openml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e525b4fe1339331d5daa6023411fe644",
   "metadata": {},
   "source": [
    "Next, we define our core UnionML app functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100c6ccd4885a8434aa1bcf15d9d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataset.reader(cache=True, cache_version=\"1\")\n",
    "def reader() -> pd.DataFrame:\n",
    "    dataset = fetch_openml_cached(\n",
    "        \"mnist_784\",\n",
    "        version=1,\n",
    "        cache=True,\n",
    "        as_frame=True,\n",
    "    )\n",
    "    # randomly sample a subset for faster training\n",
    "    return dataset.frame.sample(1000, random_state=42)\n",
    "\n",
    "\n",
    "@model.init\n",
    "def init(hyperparameters: dict) -> Pipeline:\n",
    "    estimator = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"classifier\", LogisticRegression()),\n",
    "        ]\n",
    "    )\n",
    "    return estimator.set_params(**hyperparameters)\n",
    "\n",
    "\n",
    "@model.trainer(cache=True, cache_version=\"1\")\n",
    "def trainer(\n",
    "    estimator: Pipeline,\n",
    "    features: pd.DataFrame,\n",
    "    target: pd.DataFrame,\n",
    ") -> Pipeline:\n",
    "    return estimator.fit(features, target.squeeze())\n",
    "\n",
    "\n",
    "@model.predictor\n",
    "def predictor(\n",
    "    estimator: Pipeline,\n",
    "    features: pd.DataFrame,\n",
    ") -> List[float]:\n",
    "    return [float(x) for x in estimator.predict(features)]\n",
    "\n",
    "\n",
    "@model.evaluator\n",
    "def evaluator(\n",
    "    estimator: Pipeline,\n",
    "    features: pd.DataFrame,\n",
    "    target: pd.DataFrame,\n",
    ") -> float:\n",
    "    return float(accuracy_score(target.squeeze(), estimator.predict(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab33662b0ffaaf2d0580996c1773e72",
   "metadata": {},
   "source": [
    "## Training a Model Locally\n",
    "\n",
    "Then we can train our model locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c00da14955f3165799c16b0b9861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator, metrics = model.train(\n",
    "    hyperparameters={\n",
    "        \"classifier__penalty\": \"l2\",\n",
    "        \"classifier__C\": 0.1,\n",
    "        \"classifier__max_iter\": 1000,\n",
    "    }\n",
    ")\n",
    "features = reader().sample(5, random_state=42).drop([\"class\"], axis=\"columns\")\n",
    "print(estimator, metrics, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c5c8e5acd2b25214934f524309e56",
   "metadata": {},
   "source": [
    "## Serving on a Gradio Widget\n",
    "\n",
    "Finally, let's create a `gradio` widget by simply using the `model.predict` method into\n",
    "the `gradio.Interface` object.\n",
    "\n",
    "Before we do this, however, we want to define a `feature_loader` function to handle the raw input\n",
    "coming from the `gradio` widget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d272989211f46e65792f5982b424a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@dataset.feature_loader\n",
    "def feature_loader(data: np.ndarray) -> pd.DataFrame:\n",
    "    return (\n",
    "        pd.DataFrame(data.ravel())\n",
    "        .transpose()\n",
    "        .rename(columns=lambda x: f\"pixel{x + 1}\")\n",
    "        .astype(float)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cbe8808f67856c71a0ec123cf28a6f",
   "metadata": {},
   "source": [
    "We also need to take care to handle the `None` case when we press\n",
    "the `clear` button on the widget using a `lambda` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42dea3f06fe2bc343a30197fa5ae84c",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(\n",
    "    fn=lambda img: img if img is None else model.predict(img)[0],\n",
    "    inputs=\"sketchpad\",\n",
    "    outputs=\"label\",\n",
    "    live=True,\n",
    "    allow_flagging=\"never\",\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2393897d4a7c591352ade21fd8ccea0a",
   "metadata": {},
   "source": [
    "You might notice that the model may not perform as well as you might expect...\n",
    "welcome to the world of machine learning practice! To obtain a better model given\n",
    "a fixed dataset, feel free to play around with the model hyperparameters or even\n",
    "switch up the model type/architecture that's defined in the `trainer` function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
